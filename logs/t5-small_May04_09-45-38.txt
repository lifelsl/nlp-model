pretrained_model_name_or_path: t5-small
text_prefix: dialogue: 
data_dir: D:\studypy\T5\NLP-HuggingFace-Tutorial-main\dialogue_generation\T5\partial_dataset
num_train_epochs: 20
train_batch_size: 8
valid_batch_size: 8
learning_rate: 5e-05
weight_decay: 0
num_warmup_steps: 1000
device: cpu
weights_dir: D:\studypy\T5\NLP-HuggingFace-Tutorial-main\dialogue_generation\T5\weights
====================================================================================================
train_loss: 3.796372890472412
train_ppl: 44.53934097290039
dev_loss: 3.238100528717041
dev_ppl: 25.485267639160156
learning_rate: 2.5e-05
====================================================================================================
train_loss: 3.330049514770508
train_ppl: 27.939725875854492
dev_loss: 3.083967447280884
dev_ppl: 21.844898223876953
learning_rate: 5e-05
====================================================================================================
train_loss: 3.2022902965545654
train_ppl: 24.588781356811523
dev_loss: 3.0286061763763428
dev_ppl: 20.66840362548828
learning_rate: 4.166666666666667e-05
====================================================================================================
train_loss: 3.1442642211914062
train_ppl: 23.20259666442871
dev_loss: 3.0027620792388916
dev_ppl: 20.14109230041504
learning_rate: 3.3333333333333335e-05
====================================================================================================
train_loss: 3.100058078765869
train_ppl: 22.19923973083496
dev_loss: 2.986720085144043
dev_ppl: 19.820566177368164
learning_rate: 2.5e-05
====================================================================================================
train_loss: 3.0679545402526855
train_ppl: 21.49788475036621
dev_loss: 2.9768598079681396
dev_ppl: 19.62609100341797
learning_rate: 1.6666666666666667e-05
====================================================================================================
train_loss: 3.0519325733184814
train_ppl: 21.156190872192383
dev_loss: 2.971686601638794
dev_ppl: 19.524822235107422
learning_rate: 8.333333333333334e-06
====================================================================================================
train_loss: 3.037280321121216
train_ppl: 20.848464965820312
dev_loss: 2.969081163406372
dev_ppl: 19.474018096923828
learning_rate: 0.0
====================================================================================================
train_loss: 3.035475730895996
train_ppl: 20.810874938964844
dev_loss: 2.969081163406372
dev_ppl: 19.474018096923828
learning_rate: 0.0
====================================================================================================
train_loss: 3.034607172012329
train_ppl: 20.792808532714844
dev_loss: 2.969081163406372
dev_ppl: 19.474018096923828
learning_rate: 0.0
====================================================================================================
train_loss: 3.0368094444274902
train_ppl: 20.83864974975586
dev_loss: 2.969081163406372
dev_ppl: 19.474018096923828
learning_rate: 0.0
====================================================================================================
train_loss: 3.0335958003997803
train_ppl: 20.77178955078125
dev_loss: 2.969081163406372
dev_ppl: 19.474018096923828
learning_rate: 0.0
====================================================================================================
train_loss: 3.0381648540496826
train_ppl: 20.866914749145508
dev_loss: 2.969081163406372
dev_ppl: 19.474018096923828
learning_rate: 0.0
====================================================================================================
train_loss: 3.038207769393921
train_ppl: 20.867809295654297
dev_loss: 2.969081163406372
dev_ppl: 19.474018096923828
learning_rate: 0.0
====================================================================================================
train_loss: 3.0404059886932373
train_ppl: 20.913732528686523
dev_loss: 2.969081163406372
dev_ppl: 19.474018096923828
learning_rate: 0.0
====================================================================================================
train_loss: 3.0380451679229736
train_ppl: 20.864416122436523
dev_loss: 2.969081163406372
dev_ppl: 19.474018096923828
learning_rate: 0.0
====================================================================================================
train_loss: 3.0388071537017822
train_ppl: 20.880321502685547
dev_loss: 2.969081163406372
dev_ppl: 19.474018096923828
learning_rate: 0.0
====================================================================================================
train_loss: 3.0335402488708496
train_ppl: 20.7706356048584
dev_loss: 2.969081163406372
dev_ppl: 19.474018096923828
learning_rate: 0.0
====================================================================================================
train_loss: 3.038245439529419
train_ppl: 20.868595123291016
dev_loss: 2.969081163406372
dev_ppl: 19.474018096923828
learning_rate: 0.0
====================================================================================================
train_loss: 3.040205478668213
train_ppl: 20.90953826904297
dev_loss: 2.969081163406372
dev_ppl: 19.474018096923828
learning_rate: 0.0
